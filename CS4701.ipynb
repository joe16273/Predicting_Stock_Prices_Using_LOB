{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WjBam-6OvKvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAZ0YC6hH4IS"
      },
      "source": [
        "**Mounting Drive to access Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHyRPuHWGIRg"
      },
      "source": [
        "**Importing Relevant Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rYoZF6MHPUQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input, Conv2D, LeakyReLU, MaxPooling2D, concatenate, LSTM, Reshape, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdW9yuF9FOwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75f5647-cf95-4d0c-da82-cd161c9831cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A0CZToBlSCyM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtCpEjge8hJe"
      },
      "source": [
        "Pre_processing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HniOTqdvhiJc"
      },
      "outputs": [],
      "source": [
        "def get_x_and_y(data): #function to separate data and labels, we studied the code referenced in the githubs on the paper to understand the pre-processing pipeline and then wrote our own code with changes in it as we thought that the referenced code had a few mistakes.\n",
        "  df1 = data[:40, :]\n",
        "  new_df1=np.transpose(df1)\n",
        "  df2= data[-5:,:]\n",
        "  new_df2= np.transpose(df2)\n",
        "\n",
        "\n",
        "  return  np.array(new_df1), np.array(new_df2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mck__RpikiQ"
      },
      "outputs": [],
      "source": [
        "def prepare_x(x,Time_frame): # function to prepare data according to timeframe\n",
        "\n",
        "  N,Price_x= x.shape[0],x.shape[1]\n",
        "  empty_arr= np.zeros([(N-Time_frame+1), Time_frame, Price_x])\n",
        "  for j in range(Time_frame,N+1):\n",
        "    empty_arr[j-Time_frame] = x[j-Time_frame:j, :]\n",
        "  empty_arr = empty_arr.reshape(empty_arr.shape + (1,))\n",
        "  return empty_arr\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRNB0U6JBh-9"
      },
      "outputs": [],
      "source": [
        "def prepare_y(y,x,prediction_horizon ,time_frame): # fucntion to create labels for time_frame\n",
        "  N= x.shape[0]\n",
        "  y_new= y[time_frame - 1:N]\n",
        "  y_new = y_new[:,prediction_horizon] - 1\n",
        "  y_new = np_utils.to_categorical(y_new, 3)\n",
        "  return y_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_SVMoutput(labels): #function to normalize SVM inputs\n",
        "  empty_arr= np.zeros(labels.shape[0])\n",
        "  for i in range(len(labels)):\n",
        "    empty_arr[i]= labels[i]-1\n",
        "  return empty_arr"
      ],
      "metadata": {
        "id": "dqacoDukALd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgJ4lyx-WOPo"
      },
      "source": [
        "Splitting the test data into training set and validation set. 80% will be training while 20% will be validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MJr_cMDW3BF"
      },
      "outputs": [],
      "source": [
        "train_1= np.loadtxt(\"/content/drive/MyDrive/CS4701/Datasets/published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Testing/Test_Dst_NoAuction_DecPre_CF_2.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDQWOVLmU6AC"
      },
      "outputs": [],
      "source": [
        "train_1_final = train_1[:, :int(np.floor(train_1.shape[1] * 0.8))]\n",
        "train_1_val = train_1[:, int(np.floor(train_1.shape[1] * 0.8)):]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MfVWqwXti8M"
      },
      "outputs": [],
      "source": [
        "validate_x,validate_y=get_x_and_y(train_1_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFtl6_hwtqEq"
      },
      "outputs": [],
      "source": [
        "train_2=np.loadtxt(\"/content/drive/MyDrive/CS4701/Datasets/published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Training/Train_Dst_NoAuction_DecPre_CF_4.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_2_final = train_2[:, :int(np.floor(train_2.shape[1] * 0.8))]\n",
        "test_2 = train_2[:, int(np.floor(train_2.shape[1] * 0.8)):]"
      ],
      "metadata": {
        "id": "mVGNnzYEN7Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd83xrLPuVI4"
      },
      "outputs": [],
      "source": [
        "train_2_x,train_2_y= get_x_and_y(train_2_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo7DSFSPuj_9"
      },
      "outputs": [],
      "source": [
        "train_2_xfinal= prepare_x(train_2_x,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPD_lW2ku7be"
      },
      "outputs": [],
      "source": [
        "train_2_yfinal= prepare_y(train_2_y,train_2_x,4,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTXL_6qvvHdJ"
      },
      "outputs": [],
      "source": [
        "test_2_x,test_2_y= get_x_and_y(test_2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_xfinal= prepare_x(test_2_x,100)"
      ],
      "metadata": {
        "id": "qWdHw816OZCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_yfinal= prepare_y(test_2_y,test_2_x,4,100)"
      ],
      "metadata": {
        "id": "qf9V2wAmPO8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUiGGLgEXSXo"
      },
      "outputs": [],
      "source": [
        "train_1_x,train_1_y= get_x_and_y(train_1_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLtfLNL3Xlmk"
      },
      "outputs": [],
      "source": [
        "final_x_train,final_x_val= prepare_x(train_1_x,100),prepare_x(validate_x,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dntXbQoptxEy"
      },
      "outputs": [],
      "source": [
        "final_y_train,final_y_val=prepare_y(train_1_y,train_1_x,3,100),prepare_y(validate_y,validate_x,3,100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_2_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPTnqhmZQi67",
        "outputId": "e71ac24a-83c0-4bea-cb02-e4c1a1667d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(114773, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_2_xfinal.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkTgtzd_QnZq",
        "outputId": "9c378b4b-d6f6-4221-8829-b6e00ddd6db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28595, 100, 40, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(final_x_train).shape)\n",
        "print(final_x_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gks634h5Qrhc",
        "outputId": "323d858d-fd1b-4477-a7ad-138254ad0d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22729, 100, 40, 1)\n",
            "(5608, 100, 40, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(test_2_yfinal).shape)\n",
        "print(train_2_yfinal.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIcZAA-LQ29u",
        "outputId": "8faf05a6-cb6b-4ae4-cc94-76ee4c4a6347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28595, 3)\n",
            "(114674, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data = np.loadtxt(\"/content/drive/MyDrive/CS4701/Datasets/published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Testing/Test_Dst_NoAuction_DecPre_CF_2.txt\")"
      ],
      "metadata": {
        "id": "ZCYQhLpX6G9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_x,testing_y= get_x_and_y(testing_data)"
      ],
      "metadata": {
        "id": "1vKFmLbW6k6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_final_x= prepare_x(testing_x,100)"
      ],
      "metadata": {
        "id": "GyJG2jdS60Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_final_y= prepare_y(testing_y,testing_x,4,100)"
      ],
      "metadata": {
        "id": "T1Ckprj966W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_train2= train_2_yfinal.flatten()"
      ],
      "metadata": {
        "id": "6XcnWBZuKOlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_train1= train_2_xfinal.flatten()"
      ],
      "metadata": {
        "id": "x79AWvQDcKNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_2_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIAPG-rxb-o2",
        "outputId": "517baef9-f0f0-48ac-d85b-cd9753339861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(114773, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Model using Supervised machine learning"
      ],
      "metadata": {
        "id": "nK2aWQViKQbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SGDClassifier(loss='hinge')\n",
        "\n",
        "# Fit the model\n",
        "svm.fit(train_2_x,train_2_y[:,4])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq3pFu7tKRsH",
        "outputId": "b53f3467-e875-4975-fbef-dee077cef2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_prediction = svm.predict(testing_x) # predicting labels"
      ],
      "metadata": {
        "id": "OByYTnDM-sHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_arr1,new_arr2= normalize_SVMoutput(svm_prediction),normalize_SVMoutput(testing_y[:,4]) # Comparing SVM prediction using Prediction Horizon 4"
      ],
      "metadata": {
        "id": "UuZ2qFNv_qlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_arr3,new_arr4= normalize_SVMoutput(svm_prediction),normalize_SVMoutput(testing_y[:,3]) # Comparing SVM prediction using Prediction Horizon 3"
      ],
      "metadata": {
        "id": "y7PP9jadIixR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(new_arr2,new_arr1))\n",
        "print(accuracy_score(new_arr2,new_arr1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBNJ-VNUBzG1",
        "outputId": "d5fd07c9-4a55-4409-968d-c7c90a1a3974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.39      0.56      0.46     10931\n",
            "         1.0       0.23      0.03      0.05      6462\n",
            "         2.0       0.45      0.48      0.46     11142\n",
            "\n",
            "    accuracy                           0.41     28535\n",
            "   macro avg       0.36      0.36      0.33     28535\n",
            "weighted avg       0.38      0.41      0.37     28535\n",
            "\n",
            "0.4100928684072192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(new_arr4,new_arr3))\n",
        "print(accuracy_score(new_arr4,new_arr3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnsVGEoPI6Bg",
        "outputId": "841b5674-5a9c-4857-ee2d-6b68d174ef16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.32      0.56      0.41      9091\n",
            "         1.0       0.35      0.03      0.05     10211\n",
            "         2.0       0.38      0.49      0.43      9233\n",
            "\n",
            "    accuracy                           0.35     28535\n",
            "   macro avg       0.35      0.36      0.30     28535\n",
            "weighted avg       0.35      0.35      0.29     28535\n",
            "\n",
            "0.34659190467846507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em9FcIAyX12K"
      },
      "source": [
        "CNN-LSTM Model Parameters and Architecture using Paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ald0mlm6X0u3"
      },
      "outputs": [],
      "source": [
        "filter_size= 16 #for convolution\n",
        "alpha_no = 0.01\n",
        "lstm_size= 64\n",
        "inception_size= 32\n",
        "kernel_size_1=(1,2)\n",
        "kernel_size_2=(4,1)\n",
        "kernel_size_3= (1,10)\n",
        "kernel_size_4= (1,1)\n",
        "kernel_size_5= (3,1)\n",
        "kernel_size_6=(5,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckg1ure-Y6sc"
      },
      "outputs": [],
      "source": [
        "def cnn_model_2(time_frame, entries, lstm_size,inception_size,filter_size,alpha):\n",
        "  tensor= Input(shape= (time_frame,entries,1))\n",
        "\n",
        "  #convolution according to paper details\n",
        "  layer_1= Conv2D(filter_size,kernel_size_1,strides=(1,2))(tensor)\n",
        "  layer_1= LeakyReLU(alpha= alpha_no)(layer_1)\n",
        "  layer_1 = Conv2D(filter_size,kernel_size_2 , padding='same')(layer_1)\n",
        "  layer_1 = LeakyReLU(alpha=alpha_no)(layer_1)\n",
        "  layer_1 = Conv2D(filter_size, kernel_size_2, padding='same')(layer_1)\n",
        "  layer_1 = LeakyReLU(alpha=alpha_no)(layer_1)\n",
        "\n",
        "  layer_2 = Conv2D(filter_size, kernel_size_1, strides=(1, 2))(layer_1)\n",
        "  layer_2 = LeakyReLU(alpha=alpha_no)(layer_2)\n",
        "  layer_2 = Conv2D(filter_size,kernel_size_2, padding='same')(layer_2)\n",
        "  layer_2 = LeakyReLU(alpha=alpha_no)(layer_2)\n",
        "  layer_2 = Conv2D(filter_size, kernel_size_2, padding='same')(layer_2)\n",
        "  layer_2 = LeakyReLU(alpha=alpha_no)(layer_2)\n",
        "\n",
        "  layer_3 = Conv2D(filter_size,kernel_size_3 )(layer_2)\n",
        "  layer_3 = LeakyReLU(alpha=alpha_no)(layer_3)\n",
        "  layer_3 = Conv2D(filter_size, kernel_size_2, padding='same')(layer_3)\n",
        "  layer_3 = LeakyReLU(alpha=alpha_no)(layer_3)\n",
        "  layer_3 = Conv2D(filter_size, kernel_size_2, padding='same')(layer_3)\n",
        "  layer_3 = LeakyReLU(alpha=alpha_no)(layer_3)\n",
        "\n",
        "  inception_1 = Conv2D(inception_size, kernel_size_4, padding='same')(layer_3)\n",
        "  inception_1 = LeakyReLU(alpha=alpha_no)(inception_1)\n",
        "  inception_1 = Conv2D(inception_size, kernel_size_5, padding='same')(inception_1)\n",
        "  inception_1 = LeakyReLU(alpha=alpha_no)(inception_1)\n",
        "\n",
        "  inception_2 = Conv2D(inception_size, kernel_size_4, padding='same')(layer_3)\n",
        "  inception_2 = LeakyReLU(alpha=alpha_no)(inception_2)\n",
        "  inception_2 = Conv2D(inception_size, kernel_size_6, padding='same')(inception_2)\n",
        "  inception_2 = LeakyReLU(alpha=alpha_no)(inception_2)\n",
        "\n",
        "  inception_3 = MaxPooling2D(kernel_size_5, strides=(1,1), padding='same')(layer_3)\n",
        "  inception_3 = Conv2D(inception_size, kernel_size_4, padding='same')(inception_3)\n",
        "  inception_3 = LeakyReLU(alpha=alpha_no)(inception_3)\n",
        "\n",
        "  combined_layers= keras.layers.concatenate([inception_1, inception_2, inception_3], axis=3)\n",
        "  combined_final = keras.layers.Reshape((combined_layers.shape[1], combined_layers.shape[3]))(combined_layers)\n",
        "  combined_final = keras.layers.Dropout(0.2, noise_shape=(None, 1, int(combined_final.shape[2])))(combined_final, training=True)\n",
        "\n",
        "  lstm = keras.layers.LSTM(lstm_size)(combined_final)\n",
        "\n",
        "  out = keras.layers.Dense(3, activation='softmax')(lstm)\n",
        "  model = Model(inputs=tensor, outputs=out)\n",
        "  opt = keras.optimizers.Adam(lr=0.0001)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model_2_no_dropout(time_frame, entries, lstm_size,inception_size,filter_size,alpha):\n",
        "  tensor= Input(shape= (time_frame,entries,1))\n",
        "\n",
        "  #convolution according to paper details\n",
        "  layer_1= Conv2D(filter_size,kernel_size_1,strides=(1,2))(tensor)\n",
        "  layer_1= LeakyReLU(alpha= alpha_no)(layer_1)\n",
        "  layer_1 = Conv2D(filter_size,kernel_size_2 , padding='same')(layer_1)\n",
        "  layer_1 = LeakyReLU(alpha=alpha_no)(layer_1)\n",
        "  layer_1 = Conv2D(filter_size, kernel_size_2, padding='same')(layer_1)\n",
        "  layer_1 = LeakyReLU(alpha=alpha_no)(layer_1)\n",
        "\n",
        "  layer_2 = Conv2D(filter_size, kernel_size_1, strides=(1, 2))(layer_1)\n",
        "  layer_2 = LeakyReLU(alpha=alpha_no)(layer_2)\n",
        "  layer_2 = Conv2D(filter_size,kernel_size_2, padding='same')(layer_2)\n",
        "  layer_2 = LeakyReLU(alpha=alpha_no)(layer_2)\n",
        "  layer_2 = Conv2D(filter_size, kernel_size_2, padding='same')(layer_2)\n",
        "  layer_2 = LeakyReLU(alpha=alpha_no)(layer_2)\n",
        "\n",
        "  layer_3 = Conv2D(filter_size,kernel_size_3 )(layer_2)\n",
        "  layer_3 = LeakyReLU(alpha=alpha_no)(layer_3)\n",
        "  layer_3 = Conv2D(filter_size, kernel_size_2, padding='same')(layer_3)\n",
        "  layer_3 = LeakyReLU(alpha=alpha_no)(layer_3)\n",
        "  layer_3 = Conv2D(filter_size, kernel_size_2, padding='same')(layer_3)\n",
        "  layer_3 = LeakyReLU(alpha=alpha_no)(layer_3)\n",
        "\n",
        "  inception_1 = Conv2D(inception_size, kernel_size_4, padding='same')(layer_3)\n",
        "  inception_1 = LeakyReLU(alpha=alpha_no)(inception_1)\n",
        "  inception_1 = Conv2D(inception_size, kernel_size_5, padding='same')(inception_1)\n",
        "  inception_1 = LeakyReLU(alpha=alpha_no)(inception_1)\n",
        "\n",
        "  inception_2 = Conv2D(inception_size, kernel_size_4, padding='same')(layer_3)\n",
        "  inception_2 = LeakyReLU(alpha=alpha_no)(inception_2)\n",
        "  inception_2 = Conv2D(inception_size, kernel_size_6, padding='same')(inception_2)\n",
        "  inception_2 = LeakyReLU(alpha=alpha_no)(inception_2)\n",
        "\n",
        "  inception_3 = MaxPooling2D(kernel_size_5, strides=(1,1), padding='same')(layer_3)\n",
        "  inception_3 = Conv2D(inception_size, kernel_size_4, padding='same')(inception_3)\n",
        "  inception_3 = LeakyReLU(alpha=alpha_no)(inception_3)\n",
        "\n",
        "  combined_layers= keras.layers.concatenate([inception_1, inception_2, inception_3], axis=3)\n",
        "  combined_final = keras.layers.Reshape((combined_layers.shape[1], combined_layers.shape[3]))(combined_layers)\n",
        "\n",
        "  lstm = keras.layers.LSTM(lstm_size)(combined_final)\n",
        "\n",
        "  out = keras.layers.Dense(3, activation='softmax')(lstm)\n",
        "  model = Model(inputs=tensor, outputs=out)\n",
        "  opt = keras.optimizers.Adam(lr=0.0001)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "MMw-8ShuuFYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0NrqisIo7Ub",
        "outputId": "275f6d6d-faa5-47b9-db4c-ab9d155d3a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model_new= cnn_model_2(100,40, lstm_size,inception_size, filter_size,alpha_no)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_nodropout= cnn_model_2_no_dropout(100,40, lstm_size,inception_size, filter_size,alpha_no)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1rhn25Fuz5b",
        "outputId": "5acdb7a6-26a6-48a7-b34a-72e46a56abe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4qqhQOMX1S8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNX0PAvqrnwU"
      },
      "outputs": [],
      "source": [
        "model_new.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/drive/MyDrive/CS4701/checkpoints/\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='auto',\n",
        "    save_best_only=True)\n",
        "\n",
        "model_new.fit(train_2_xfinal, train_2_yfinal, validation_data=(test_2_xfinal,test_2_yfinal),\n",
        "            epochs=100, batch_size=32, verbose=2, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "NT91dYs7vFF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qozJhrbxsDzc"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiEwSakPsFdW",
        "outputId": "465c4d15-51c1-4f82-d4a1-b8c202b26390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3584/3584 - 502s - loss: 1.0280 - accuracy: 0.4218 - val_loss: 1.0968 - val_accuracy: 0.3736 - 502s/epoch - 140ms/step\n",
            "Epoch 2/100\n",
            "3584/3584 - 519s - loss: 0.9858 - accuracy: 0.4386 - val_loss: 1.0832 - val_accuracy: 0.3761 - 519s/epoch - 145ms/step\n",
            "Epoch 3/100\n",
            "3584/3584 - 521s - loss: 0.9131 - accuracy: 0.4758 - val_loss: 1.0182 - val_accuracy: 0.4863 - 521s/epoch - 145ms/step\n",
            "Epoch 4/100\n",
            "3584/3584 - 518s - loss: 0.8909 - accuracy: 0.4882 - val_loss: 0.9643 - val_accuracy: 0.4901 - 518s/epoch - 145ms/step\n",
            "Epoch 5/100\n",
            "3584/3584 - 521s - loss: 0.8810 - accuracy: 0.4969 - val_loss: 1.0726 - val_accuracy: 0.4293 - 521s/epoch - 145ms/step\n",
            "Epoch 6/100\n",
            "3584/3584 - 518s - loss: 0.8713 - accuracy: 0.5026 - val_loss: 0.9287 - val_accuracy: 0.4985 - 518s/epoch - 144ms/step\n",
            "Epoch 7/100\n",
            "3584/3584 - 519s - loss: 0.8621 - accuracy: 0.5160 - val_loss: 0.9429 - val_accuracy: 0.4800 - 519s/epoch - 145ms/step\n",
            "Epoch 8/100\n",
            "3584/3584 - 517s - loss: 0.8503 - accuracy: 0.5436 - val_loss: 0.9375 - val_accuracy: 0.4944 - 517s/epoch - 144ms/step\n",
            "Epoch 9/100\n",
            "3584/3584 - 517s - loss: 0.8279 - accuracy: 0.5756 - val_loss: 0.9405 - val_accuracy: 0.5074 - 517s/epoch - 144ms/step\n",
            "Epoch 10/100\n",
            "3584/3584 - 512s - loss: 0.8028 - accuracy: 0.6015 - val_loss: 0.9521 - val_accuracy: 0.4933 - 512s/epoch - 143ms/step\n",
            "Epoch 11/100\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/drive/MyDrive/CS4701/checkpoints\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='auto',\n",
        "    save_best_only=True)\n",
        "\n",
        "model_nodropout.fit(train_2_xfinal, train_2_yfinal, validation_data=(test_2_xfinal,test_2_yfinal),\n",
        "            epochs=100, batch_size=32, verbose=2, callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doXbc37Vob2u"
      },
      "source": [
        "Testing Dataset Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z4h9qmKgMIg"
      },
      "outputs": [],
      "source": [
        "test_1= np.loadtxt(\"/content/drive/MyDrive/CS4701/Datasets/published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Testing/Test_Dst_NoAuction_DecPre_CF_5.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKPH9cQTo-TB"
      },
      "outputs": [],
      "source": [
        "test_1_x, test_1_y= get_x_and_y(test_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXaj74Fgo-cm"
      },
      "outputs": [],
      "source": [
        "test_1_xfinal= prepare_x(test_1_x,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kiR9ZippVJk"
      },
      "outputs": [],
      "source": [
        "test_1_yfinal= prepare_y(test_1_y,test_1_x,3,100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyUNZoDGlpmv"
      },
      "source": [
        "Model Evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c1MuQWqlryK"
      },
      "outputs": [],
      "source": [
        "a= model_new.load_weights(\"/content/drive/MyDrive/CS4701/checkpoints\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtkhNI-tnZ9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdf9d11-072b-457d-f004-8302a4790ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "889/889 [==============================] - 65s 72ms/step\n"
          ]
        }
      ],
      "source": [
        "pred2= model_nodropout.predict(testing_final_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxPuuirvoRdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd46edf-bfb5-4943-dce1-ef33703aad97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "889/889 [==============================] - 44s 48ms/step\n"
          ]
        }
      ],
      "source": [
        "pred = model_new.predict(testing_final_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXLh5Vvvpxz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4020a00f-6197-4c16-cb1a-3930ada5cbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score: 0.7054086369390913\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6828    0.7470    0.7135     10906\n",
            "           1     0.8301    0.5732    0.6781      6434\n",
            "           2     0.6818    0.7412    0.7103     11096\n",
            "\n",
            "    accuracy                         0.7054     28436\n",
            "   macro avg     0.7316    0.6871    0.7006     28436\n",
            "weighted avg     0.7158    0.7054    0.7042     28436\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('accuracy_score:', accuracy_score(np.argmax(testing_final_y, axis=1), np.argmax(pred, axis=1)))\n",
        "print(classification_report(np.argmax(testing_final_y, axis=1), np.argmax(pred, axis=1), digits=4)) # source for this code is listed in the paper references"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy_score:', accuracy_score(np.argmax(testing_final_y, axis=1), np.argmax(pred2, axis=1)))\n",
        "print(classification_report(np.argmax(testing_final_y, axis=1), np.argmax(pred2, axis=1), digits=4))"
      ],
      "metadata": {
        "id": "GHRKgoe6TatV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}